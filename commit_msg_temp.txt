feat: Gather CSV headers and draft initial PDF schema

This commit introduces a script and its output, which collects
header information from all CSV files in the repository. This
evidence is crucial for analyzing existing data formats and
defining new, explicit schemas.

Additionally, this commit includes the initial draft or update
of `rules/jordyn_pdf_v1.yaml`, which is based on the
gathered header evidence for PDF-extracted CSVs. This new schema
aims to address the gap where PDF-extracted CSVs for Jordyn
were falling back to `generic_csv`, leading to incomplete
merchant data.

Key outcomes:
- Added `logs/schema_evidence/complete_csv_headers_20250522_193514.txt`
  containing relative paths, file sizes, and header rows for all
  CSVs under `C:\BALANCE\BALANCE-pyexcel-repository\CSVs`.
- Created/Updated `rules/jordyn_pdf_v1.yaml` based on the
  analysis of these headers, providing an explicit schema for
  Jordyn's PDF-derived transaction data.

The process involved:
1. Executing a PowerShell script to iterate through CSVs.
2. Capturing the first line (header) of each file.
3. Storing this information along with file metadata in a
   timestamped log file.
4. Analyzing the collected headers to inform the structure of
   `rules/jordyn_pdf_v1.yaml`.

This step is part of a broader effort to improve data ingestion
reliability and accuracy by moving away from generic CSV parsing
towards explicit schema definitions for all known data sources.
