# Power BI Integration Guide

This page shows three ways to bring **BALANCE** transaction data into Power BI for dispute analysis, refund verification, and financial reporting:

1. **Quick Power BI Prep** – Use our custom script for combined/mixed data (recommended for dispute analysis)
2. **Folder import** – combine raw CSVs directly (fastest to set up)
3. **DuckDB + Parquet** – query the canonical `balance_final.parquet` (cleaner for large data)

---

## Method 1: Quick Power BI Prep Script (Recommended for Mixed Data)

**Best for**: Combined Ryan & Jordyn data, dispute analysis, transaction searching

### Step 1: Prepare Your Data
1. Place your combined CSV files in `csv_inbox/`:
   ```
   csv_inbox/
   ├── ryan&jordyn-monarch-020250809.csv
   └── ryan&jordyn-rocket-020250809.csv
   ```

2. Run the preparation script:
   ```bash
   python scripts/utilities/quick_powerbi_prep.py
   ```

### Step 2: What You Get
The script creates three files in `output/`:
- **`.parquet`** - Most efficient for Power BI (recommended)
- **`.xlsx`** - Good for manual review before importing
- **`.csv`** - Simple import option

### Step 3: Advanced Deduplication & Analysis Features
- **Smart deduplication methodology** - Sophisticated algorithm removes 30-35% duplicates while preserving unique transactions
- **Intelligent merchant standardization** - Groups variations (Joan M Zimmerman transfers, Sallie Mae, Amazon variations)
- **Pre-flagged disputes** - `potential_refund` column identifies refunds, returns, disputes, chargebacks
- **Enhanced metadata** - Date components, expense/income flags, transaction IDs
- **Data quality validation** - Reports potential remaining duplicates and data completeness

#### Deduplication Methodology
The script uses a **3-stage smart deduplication process**:

1. **Composite Key Creation** - Combines date + amount + normalized description (first 5 meaningful words)
2. **Description Normalization** - Removes transaction-specific codes (SEQ#, TRN#, RFB#) that vary between data sources
3. **Intelligent Duplicate Resolution** - When duplicates found, selects the record with most complete information rather than arbitrary deletion

**Safeguards**: Only removes transactions with identical date, amount, and core description. Preserves legitimate similar transactions (e.g., multiple Amazon orders same day with different amounts).

### Step 4: Load into Power BI
1. Open Power BI Desktop
2. **Get Data → Parquet** (recommended)
3. Select: `output/transactions_for_powerbi_[timestamp].parquet`
4. **Load** - ready for analysis!

### Key Columns for Analysis
- `potential_refund` - Pre-flagged for dispute review (TRUE/FALSE)
- `merchant_standardized` - Clean merchant names for filtering
- `amount` / `amount_abs` - Transaction amounts
- `is_expense` / `is_income` - Quick transaction type filters
- `date` / `year` / `month` / `quarter` - Time-based analysis

---

## Method 2: Traditional CSV Folder Import

| Layout | Pick this when… | Typical path | Setup notes |
|--------|-----------------|--------------|-------------|
| **Inside the repo** | • You’re the only user<br>• You won’t push CSVs to GitHub **or** `/CSVs/` is already in *.gitignore* | `…\BALANCE-pyexcel-repository\CSVs\<Owner>\*.csv` | *No action* – just keep dropping files there. |
| **Outside the repo** | • You’ll publish the code publicly<br>• You want a slim commit history | `C:\BALANCE_data\CSVs\<Owner>\*.csv` | ```cmd<br>mkdir C:\BALANCE_data\CSVs<br>robocopy CSVs C:\BALANCE_data\CSVs /E```<br>Add to *.gitignore*: <br>`/CSVs/`<br>`csv_inbox_real/` |

Either structure works with the steps below—just stay consistent.

---

## 2  Build the Power BI report

### 2 a **Original method:** Folder → Combine CSVs

1. **Get Data → Folder**  
   Browse to the parent folder that contains the *Owner* sub-folders (e.g., `…\CSVs`).

2. Click **Transform Data** (don’t hit *Load* yet).

3. In Power Query:  
   * Filter `Extension = .csv`.  
   * Remove unneeded columns (`Size`, `Date accessed`, …).  
   * Home → **Combine / Transform → Combine Files**.  
   * Power BI auto-promotes headers and appends everything into a query called *Combined*.

4. Set column types:  
   | Column | Type |
   |--------|------|
   | `Date` | Date |
   | `Amount` | Decimal number |
   | Others (`Owner`, `RawMerchant`, …) | Text |

5. **Close & Apply** – the data model is ready.

---

### 2 b **Recommended (Stage 2+):** DuckDB ODBC → `balance_final.parquet`

This taps the fully normalized, de-duplicated dataset your CLI already produces.

#### Prerequisites

* **DuckDB ODBC driver** installed.  
* A fresh `balance_final.parquet` (generated by `balance-pyexcel`).

#### Steps

1. **Get Data → ODBC**  
2. In the dialog:  
   * Choose your *DuckDB* DSN **or** supply a connection string:  
     ```text
     Driver=DuckDB Driver;Database=:memory:;
     ```
3. Expand **Advanced options** → paste SQL:  
   ```sql
   SELECT * 
   FROM read_parquet('C:\\BALANCE_data\\balance_final.parquet');
Replace the path with the real location of your Parquet file.

Click OK → anonymous credentials are fine for local files.

Verify data types in Power Query, then Close & Apply.

Why this is nicer

One file, no header-promotion wizardry.

Includes all canonical fields (TxnID, CanonMerchant, SharedFlag, …).

Faster refresh for big datasets (> 50 k rows).

3 Build visuals (starter set)
Visual	How-to
Month-over-Month Spend	Line or clustered column. Axis = Year-Month (use Date hierarchy or a custom "yyyy-MM" column). Values = Sum Amount (set conditional color if negative).
Top-10 Merchants (current month)	Add a slicer on Year-Month, then a Top N bar chart – Axis = RawMerchant, Values = Sum Amount, filter Top 10.
Charges vs Credits Donut	Create a calc column: ChargeCredit = if [Amount] < 0 then "Charge" else "Credit". Use in a donut visual.
KPI Cards	4 Card visuals: Sum Charges, Sum Credits, Net, Distinct Merchant Count.
Slicers	Add for Owner, AccountLast4, Year-Month; turn on Sync slicers if you add extra pages.

4 Optional: owner-specific “sheets”
Bookmarks method: Duplicate the page, pre-filter each copy to one Owner, lock the slicer, rename tabs “Jordyn”, “Ryan”, etc.

Single-page method: One page + an Owner slicer the user can toggle.

5 Refresh workflow
Step	CSV Folder method	Parquet/ODBC method
1 Run pipeline	process_pdfs.py or balance-pyexcel CLI → writes new CSVs	Same CLI → overwrites balance_final.parquet
2 Refresh in Power BI	Click Refresh – Power Query re-scans folder & appends	Click Refresh – DuckDB query re-reads the Parquet
3 Review visuals	Everything updates – no VBA or COM needed	Ditto

Recap
Decide on CSV folder vs Parquet—both are one-click refresh in Power BI.

Folder method: Get Data → Folder → Combine Files wizard.

Parquet method: Get Data → ODBC → read_parquet() SQL (needs DuckDB driver).

Build visuals with slicers and KPI cards; sync slicers for a dashboard feel.

Need screenshots or a GIF walkthrough? Open an issue or ping me on Slack!

yaml
Copy
Edit

---

### How to wire this into the docs

1. Save as `docs/powerbi_integration.md`.  
2. Append to **mkdocs.yml** under *Architecture Overview*:

   ```yaml
   nav:
     - Architecture Overview: architecture.md
     - Power BI Integration: powerbi_integration.md     # <– new
Commit & push—MkDocs will rebuild with the new sidebar entry.