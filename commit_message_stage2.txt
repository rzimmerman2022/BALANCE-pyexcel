feat(pipeline): implement Stage 2 refactor with data-driven merchants and two-way sync

This commit implements the Stage 2 refactor for the BALANCE-pyexcel project, introducing data-driven merchant normalization, robust two-way synchronization of manual classifications, updated documentation, comprehensive unit/integration tests, and a CI workflow.

Key changes include:

**1. Merchant Cleaning Refactor:**
   - Modified `src/balance_pipeline/normalize.py` to dynamically load merchant cleaning rules from `rules/merchant_lookup.csv`, replacing previous hard-coded regex list.
   - Added a header (`pattern,canonical`) to `rules/merchant_lookup.csv`.
   - Implemented lazy loading and a module-level cache for these lookup rules to optimize performance.
   - Integrated robust validation for regex patterns during the loading process:
     - Invalid regex patterns in the CSV now raise a `ValueError`, ensuring CI failure and early error detection.
     - Malformed CSV structure (e.g., incorrect header, wrong number of columns per row) is handled with warnings and skips problematic rows, or raises `ValueError` for critical issues like bad headers.
     - `FileNotFoundError` for the lookup CSV is handled gracefully, allowing the system to proceed with fallback cleaning logic.
   - The `clean_merchant` function now iterates through these compiled regex rules, applying the first matching canonical name, and defaults to a generic cleaning mechanism (`_clean_desc().title()`) if no rules match.

**2. Two-Way Sync of Manual Classifications:**
   - Enhanced `src/balance_pipeline/cli.py` to establish a two-way synchronization mechanism for `SharedFlag` and `SplitPercent` classifications.
   - The CLI process now initiates by loading the existing state of classifications from the canonical `balance_final.parquet` file.
   - Data ingested from current CSV sources (via `etl_main`) is then merged with this canonical data, preserving prior classifications for existing transactions. New transactions receive default classifications.
   - Manual edits made by users in the `Queue_Review` sheet of the Excel workbook are read and applied as the final override ("last edit wins") to the merged dataset via the `sync_review_decisions` function.
   - The fully reconciled DataFrame, reflecting all data sources and manual overrides, is then persisted back to both `balance_final.parquet` (overwriting it) and the `Transactions` sheet in the Excel workbook.

**3. Documentation Updates:**
   - Updated `docs/power_bi_workflow.md` to include a new detailed section (2b) on connecting Power BI directly to the `balance_final.parquet` file using the DuckDB ODBC driver.
   - This new section outlines prerequisites, step-by-step connection instructions in Power BI, and advantages of this method. Placeholders for screenshots are included.
   - The "Refresh workflow" and "Quick recap" portions of the document were also revised to incorporate this new Parquet/ODBC data sourcing option.

**4. Comprehensive Testing:**
   - **Merchant Lookup Tests (`tests/test_normalize.py`):**
     - Added extensive unit tests covering the successful loading and application of rules from `merchant_lookup.csv`.
     - Verified correct fallback behavior for `clean_merchant` when no rules match or the lookup file is missing/empty.
     - Ensured proper error handling and `ValueError` exceptions for invalid regex patterns and malformed CSV files (header/row issues).
     - Tested graceful handling of non-string inputs by `clean_merchant`.
     - Utilized `pytest` fixtures (`tmp_path`, `monkeypatch`, `caplog`) and `importlib.reload` for isolated testing of module-level loading logic.
   - **Sync Routine Tests (`tests/test_sync.py`):**
     - Implemented unit tests for the `sync_review_decisions` function in `src/balance_pipeline/sync.py`.
     - Test cases cover happy paths for 'Y', 'N', 'S' decisions, validation of `SplitPercent` values (including default for missing, clamping for out-of-bounds), and correct handling of invalid or empty decision inputs from the queue.
     - Ensured that transactions not present in the queue, or queue entries for non-existent transactions, are handled correctly.
     - Verified that other transaction data columns are preserved during the sync process.
   - **CLI Integration Tests (`tests/test_cli_integration.py`):**
     - Added integration tests for the command-line interface's synchronization logic.
     - One key test simulates the complete flow: loading an initial `balance_final.parquet`, processing new CSVs, merging data, applying `Queue_Review` sheet overrides, and verifying the final state of `balance_final.parquet` and the Excel `Transactions` sheet.
     - Another test verifies the CLI's robustness when the `Queue_Review` sheet is malformed (e.g., missing required columns), ensuring it logs a warning and skips the sync step gracefully.
     - These tests use `subprocess` to invoke the CLI and `pandas` for data validation.

**5. Continuous Integration (CI):**
   - Created a new GitHub Actions workflow file at `.github/workflows/ci.yml`.
   - This workflow is configured to trigger on push and pull_request events targeting the `main` branch.
   - It executes on an `ubuntu-latest` runner, using Python 3.11.
   - The CI pipeline includes steps for:
     1. Checking out the repository.
     2. Setting up Python and caching pip dependencies.
     3. Installing Poetry.
     4. Installing project dependencies using `poetry install`.
     5. Linting the codebase with `poetry run ruff check .`.
     6. Running all tests with `poetry run pytest -q tests/`.

**6. README Update:**
   - Updated the placeholder URL for the CI status badge in `README.md` to `your-github-org-or-username/BALANCE-pyexcel`, providing a more specific template for the user to customize.

This set of changes significantly enhances the robustness, maintainability, and usability of the BALANCE-pyexcel pipeline.
