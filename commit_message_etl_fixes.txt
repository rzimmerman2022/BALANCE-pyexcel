feat: Resolve Parquet output and data processing issues in ETL pipeline

This commit addresses several issues identified in the ETL pipeline, ensuring that the Parquet output correctly reflects the cleaned and master-schema-indexed data, rather than raw unprocessed frames.

Key changes and improvements:

1.  **Schema Registry (`rules/schema_registry.yml`):**
    *   Updated `column_map` for multiple schemas (`chase_total_checking`, `discover_it_card`, `wells_fargo_card`, `monarch_export`, `rocket_money`, `jordyn_pdf_document`, `jordyn_pdf`, `test_data_source1`, `test_data_source2`) to correctly map source descriptive fields to `OriginalDescription`. This ensures proper data flow for merchant cleaning and TxnID generation.
    *   Standardized `Institution` mapping: Changed `Bank` to `Institution` for `wells_fargo_card`, `monarch_export`, `rocket_money`, `jordyn_pdf_document`, `jordyn_pdf`, and test schemas to align with `MASTER_SCHEMA_COLUMNS`.
    *   Adjusted `discover_it_card` schema:
        *   Mapped source `Transaction Type` to `AccountType`.
        *   Changed `sign_rule` from a complex rule (which relied on a non-existent `Transaction Type` column in source CSVs) to `flip_if_positive`, a more robust default for credit card statements.

2.  **CSV Consolidator (`src/balance_pipeline/csv_consolidator.py`):**
    *   **TxnID Generation (`_generate_txn_id`, `process_csv_files`):**
        *   Refined `TXN_ID_HASH_COLS` to `["Date", "Amount", "OriginalDescription", "Account"]`. Removed `PostDate` and `Institution` as they are not reliably available across all data sources, making TxnID generation more robust.
        *   The `_generate_txn_id` function was already updated to handle missing values in hash components gracefully (using empty strings).
        *   Removed the explicit pre-check for `missing_hash_cols` in `process_csv_files` before calling `_generate_txn_id`, as the function itself is now robust enough.
    *   **Sign Rule Implementation (`apply_schema_transformations`):**
        *   Implemented the `flip_if_withdrawal` sign rule for the `chase_total_checking` schema. This rule flips the amount to negative if the `Category` is 'withdrawal' or 'payment' and the amount is positive.
    *   **Logging Enhancements:** Added various `log.info` and `log.warning` statements as requested to trace DataFrame shapes, schema matching, unexpected columns, and merchant blank counts.
    *   **Re-indexing in `process_csv_files`**: Confirmed that `processed_df = processed_df.reindex(columns=MASTER_SCHEMA_COLUMNS, fill_value=pd.NA)` is correctly applied to ensure individual dataframes conform to the master schema before concatenation.

3.  **CLI (`src/balance_pipeline/cli.py`):**
    *   **TypeError Fix for `SharedFlag`**: Resolved a `TypeError: Invalid value '?' for dtype boolean`. Ensured that `SharedFlag` column is consistently treated as `pd.BooleanDtype()` and that `pd.NA` is used for missing values instead of the string `'?'` during `fillna` operations after merging DataFrames. Similar safeguards were applied to `SplitPercent` to ensure it remains float.
    *   **Queue Review Template (`_create_queue_review_template`):**
        *   Corrected the context column list to use `OriginalDescription` instead of `Description` when populating sample rows, aligning with the actual column name in the DataFrame at that stage. This resolves warnings about missing context columns for the template.
    *   **Logging for Final DataFrame Shape**: Added `log.info("⚙️ Final DF columns (%d): %s", len(df.columns), list(df.columns))` before writing the Parquet file to confirm final column structure.

These changes collectively ensure that the data processing is more accurate, robust, and that the final Parquet output adheres to the master schema with correctly processed data.
