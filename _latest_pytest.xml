<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="15" skipped="0" tests="70" time="12.228" timestamp="2025-05-18T18:50:37.789549-07:00" hostname="DESKTOP-D0MGLOG"><testcase classname="tests.test_cli_full_flow" name="test_full_cli_workflow" time="1.184" /><testcase classname="tests.test_cli_full_flow" name="test_cli_prefer_rocket_behavior" time="0.542"><failure message="AssertionError: Should have kept the Rocket version&#10;assert 'Monarch' == 'Rocket'&#10;  &#10;  - Rocket&#10;  + Monarch">tests\test_cli_full_flow.py:228: in test_cli_prefer_rocket_behavior
    assert txn_rows.iloc[0]["Source"] == "Rocket", "Should have kept the Rocket version"
E   AssertionError: Should have kept the Rocket version
E   assert 'Monarch' == 'Rocket'
E     
E     - Rocket
E     + Monarch</failure></testcase><testcase classname="tests.test_cli_integration" name="test_cli_dry_run[xlsx]" time="0.603"><failure message="AssertionError: Dry run CSV should contain 3 transactions from sample CSVs&#10;assert 1 == 3&#10; +  where 1 = len(              TxnID         Owner  ...  Description       Source\n0  2edf2958166561c5  UnknownOwner  ...          NaN  TestSource1\n\n[1 rows x 29 columns])">tests\test_cli_integration.py:100: in test_cli_dry_run
    assert len(df) == 3, "Dry run CSV should contain 3 transactions from sample CSVs"
E   AssertionError: Dry run CSV should contain 3 transactions from sample CSVs
E   assert 1 == 3
E    +  where 1 = len(              TxnID         Owner  ...  Description       Source\n0  2edf2958166561c5  UnknownOwner  ...          NaN  TestSource1\n\n[1 rows x 29 columns])</failure></testcase><testcase classname="tests.test_cli_integration" name="test_cli_dry_run[xlsm]" time="0.591"><failure message="AssertionError: Dry run CSV should contain 3 transactions from sample CSVs&#10;assert 1 == 3&#10; +  where 1 = len(              TxnID         Owner  ...  Description       Source\n0  2edf2958166561c5  UnknownOwner  ...          NaN  TestSource1\n\n[1 rows x 29 columns])">tests\test_cli_integration.py:100: in test_cli_dry_run
    assert len(df) == 3, "Dry run CSV should contain 3 transactions from sample CSVs"
E   AssertionError: Dry run CSV should contain 3 transactions from sample CSVs
E   assert 1 == 3
E    +  where 1 = len(              TxnID         Owner  ...  Description       Source\n0  2edf2958166561c5  UnknownOwner  ...          NaN  TestSource1\n\n[1 rows x 29 columns])</failure></testcase><testcase classname="tests.test_cli_integration" name="test_cli_xlsm_processing_creates_temp_file[xlsm]" time="0.600"><failure message="Failed: Failed to read temp XLSX file: Transactions sheet should contain 3 txns&#10;assert 1 == 3&#10; +  where 1 = len(              TxnID         Owner  ...  Description       Source\n0  2edf2958166561c5  UnknownOwner  ...          NaN  TestSource1\n\n[1 rows x 29 columns])&#10;CLI STDOUT:&#10;2025-05-18 18:50:41,789 - DEBUG - Logging configured. Level: DEBUG. Handlers: [None]&#10;2025-05-18 18:50:41,789 - INFO - ==================================================&#10;2025-05-18 18:50:41,789 - INFO - Starting BALANCE-pyexcel CLI process (full ETL mode)...&#10;2025-05-18 18:50:41,789 - DEBUG - Arguments received (full ETL mode): inbox='C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\csv_inbox', workbook='C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.xlsm'&#10;2025-05-18 18:50:41,789 - DEBUG - Resolved Inbox Path: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\csv_inbox&#10;2025-05-18 18:50:41,789 - DEBUG - Resolved Workbook Path: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.xlsm&#10;2025-05-18 18:50:41,790 - DEBUG - Created lock file: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.xlsm.lock&#10;2025-05-18 18:50:41,790 - INFO - Canonical Parquet file not found at C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\balance_final.parquet. Will create if not dry run. Starting with empty canonical data.&#10;2025-05-18 18:50:41,790 - INFO - Starting ETL process for inbox: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\csv_inbox&#10;2025-05-18 18:50:41,791 - INFO - Found 2 CSV files to process: ['data_source1.csv', 'data_source2.csv']&#10;2025-05-18 18:50:41,791 - INFO - Loading schema registry from: C:\BALANCE\BALANCE-pyexcel-repository\BALANCE-pyexcel\rules\schema_registry.yml&#10;2025-05-18 18:50:41,797 - INFO - Successfully loaded 9 schema definitions.&#10;2025-05-18 18:50:41,797 - INFO - Loading merchant lookup rules from: C:\BALANCE\BALANCE-pyexcel-repository\BALANCE-pyexcel\rules\merchant_lookup.csv&#10;2025-05-18 18:50:41,799 - INFO - Successfully loaded and compiled 10 merchant lookup rules from C:\BALANCE\BALANCE-pyexcel-repository\BALANCE-pyexcel\rules\merchant_lookup.csv.&#10;2025-05-18 18:50:41,799 - INFO - Processing CSV file: data_source1.csv&#10;2025-05-18 18:50:41,800 - INFO - Inferred Owner: 'UnknownOwner' from path.&#10;2025-05-18 18:50:41,801 - INFO - Matched schema 'test_data_source1' by filename pattern 'data_source1.csv' for file 'data_source1.csv'.&#10;2025-05-18 18:50:41,801 - INFO - Header signature also matches for schema 'test_data_source1'.&#10;2025-05-18 18:50:41,801 - INFO - Using schema 'test_data_source1' for data_source1.csv.&#10;2025-05-18 18:50:41,801 - INFO - Applying schema transformations for schema ID: 'test_data_source1'&#10;2025-05-18 18:50:41,801 - WARNING - Column 'Date' (normalized: 'date') defined in schema 'test_data_source1' column_map not found in the CSV file. It will be missing.&#10;2025-05-18 18:50:41,801 - WARNING - Column 'Description' (normalized: 'description') defined in schema 'test_data_source1' column_map not found in the CSV file. It will be missing.&#10;2025-05-18 18:50:41,801 - WARNING - Column 'Amount' (normalized: 'amount') defined in schema 'test_data_source1' column_map not found in the CSV file. It will be missing.&#10;2025-05-18 18:50:41,801 - WARNING - Column 'Account' (normalized: 'account') defined in schema 'test_data_source1' column_map not found in the CSV file. It will be missing.&#10;2025-05-18 18:50:41,801 - WARNING - Column 'Category' (normalized: 'category') defined in schema 'test_data_source1' column_map not found in the CSV file. It will be missing.&#10;2025-05-18 18:50:41,801 - WARNING - Column 'Bank' (normalized: 'bank') defined in schema 'test_data_source1' column_map not found in the CSV file. It will be missing.&#10;2025-05-18 18:50:41,802 - INFO - Applied column mapping. Renamed columns: {}&#10;2025-05-18 18:50:41,803 - INFO - Collected unmapped columns into 'Extras': ['Transaction Date', 'Details', 'Value', 'Account Name', 'Bank Name']&#10;2025-05-18 18:50:41,803 - WARNING - Amount column 'Amount' not found after mapping. Cannot apply sign rules or ensure numeric type.&#10;2025-05-18 18:50:41,803 - INFO - Populated 'DataSourceName' with 'test_data_source1'.&#10;2025-05-18 18:50:41,803 - INFO - Added static column 'Source' with value 'TestSource1'.&#10;2025-05-18 18:50:41,803 - WARNING - Unexpected column survived mapping: Transaction Date&#10;2025-05-18 18:50:41,803 - WARNING - Unexpected column survived mapping: Details&#10;2025-05-18 18:50:41,803 - WARNING - Unexpected column survived mapping: Value&#10;2025-05-18 18:50:41,803 - WARNING - Unexpected column survived mapping: Account Name&#10;2025-05-18 18:50:41,803 - WARNING - Unexpected column survived mapping: Bank Name&#10;2025-05-18 18:50:41,803 - WARNING - Neither 'OriginalDescription' nor 'Merchant' column found for merchant cleaning. Returning empty Series.&#10;2025-05-18 18:50:41,803 - INFO - Applied final merchant cleaning.&#10;2025-05-18 18:50:41,803 - INFO - #x1F6D2 Merchant blanks after clean for file data_source1.csv: 2 (100.00%)&#10;2025-05-18 18:50:41,804 - INFO - Generated 'TxnID' column.&#10;2025-05-18 18:50:41,813 - INFO - Applying reindex to MASTER_SCHEMA_COLUMNS (element 3: PostDate) with fill_value=pd.NA for data_source1.csv&#10;2025-05-18 18:50:41,814 - INFO - Finished processing data_source1.csv. 2 rows added.&#10;2025-05-18 18:50:41,814 - INFO - Processing CSV file: data_source2.csv&#10;2025-05-18 18:50:41,816 - INFO - Inferred Owner: 'UnknownOwner' from path.&#10;2025-05-18 18:50:41,816 - INFO - Matched schema 'test_data_source2' by filename pattern 'data_source2.csv' for file 'data_source2.csv'.&#10;2025-05-18 18:50:41,816 - INFO - Header signature also matches for schema 'test_data_source2'.&#10;2025-05-18 18:50:41,816 - INFO - Using schema 'test_data_source2' for data_source2.csv.&#10;2025-05-18 18:50:41,816 - INFO - Applying schema transformations for schema ID: 'test_data_source2'&#10;2025-05-18 18:50:41,816 - WARNING - Column 'Date' (normalized: 'date') defined in schema 'test_data_source2' column_map not found in the CSV file. It will be missing.&#10;2025-05-18 18:50:41,816 - WARNING - Column 'Description' (normalized: 'description') defined in schema 'test_data_source2' column_map not found in the CSV file. It will be missing.&#10;2025-05-18 18:50:41,816 - WARNING - Column 'Amount' (normalized: 'amount') defined in schema 'test_data_source2' column_map not found in the CSV file. It will be missing.&#10;2025-05-18 18:50:41,816 - WARNING - Column 'Account' (normalized: 'account') defined in schema 'test_data_source2' column_map not found in the CSV file. It will be missing.&#10;2025-05-18 18:50:41,816 - WARNING - Column 'Category' (normalized: 'category') defined in schema 'test_data_source2' column_map not found in the CSV file. It will be missing.&#10;2025-05-18 18:50:41,816 - WARNING - Column 'Bank' (normalized: 'bank') defined in schema 'test_data_source2' column_map not found in the CSV file. It will be missing.&#10;2025-05-18 18:50:41,816 - INFO - Applied column mapping. Renamed columns: {}&#10;2025-05-18 18:50:41,817 - INFO - Collected unmapped columns into 'Extras': ['Transaction Date', 'Details', 'Value', 'Account Name', 'Bank Name']&#10;2025-05-18 18:50:41,817 - WARNING - Amount column 'Amount' not found after mapping. Cannot apply sign rules or ensure numeric type.&#10;2025-05-18 18:50:41,817 - INFO - Populated 'DataSourceName' with 'test_data_source2'.&#10;2025-05-18 18:50:41,817 - INFO - Added static column 'Source' with value 'TestSource2'.&#10;2025-05-18 18:50:41,817 - WARNING - Unexpected column survived mapping: Transaction Date&#10;2025-05-18 18:50:41,817 - WARNING - Unexpected column survived mapping: Details&#10;2025-05-18 18:50:41,817 - WARNING - Unexpected column survived mapping: Value&#10;2025-05-18 18:50:41,817 - WARNING - Unexpected column survived mapping: Account Name&#10;2025-05-18 18:50:41,817 - WARNING - Unexpected column survived mapping: Bank Name&#10;2025-05-18 18:50:41,817 - WARNING - Neither 'OriginalDescription' nor 'Merchant' column found for merchant cleaning. Returning empty Series.&#10;2025-05-18 18:50:41,818 - INFO - Applied final merchant cleaning.&#10;2025-05-18 18:50:41,818 - INFO - #x1F6D2 Merchant blanks after clean for file data_source2.csv: 1 (100.00%)&#10;2025-05-18 18:50:41,818 - INFO - Generated 'TxnID' column.&#10;2025-05-18 18:50:41,826 - INFO - Applying reindex to MASTER_SCHEMA_COLUMNS (element 3: PostDate) with fill_value=pd.NA for data_source2.csv&#10;2025-05-18 18:50:41,826 - INFO - Finished processing data_source2.csv. 1 rows added.&#10;2025-05-18 18:50:41,826 - INFO - Schema matching smoke test - Counts of schema_ids found: Counter({'test_data_source1': 1, 'test_data_source2': 1})&#10;2025-05-18 18:50:41,827 - INFO - Successfully consolidated 2 CSV files into a single DataFrame with 3 total rows.&#10;2025-05-18 18:50:41,827 - INFO - #x1F6D2 Total merchant blanks in final_df after concatenation: 0 (0.00%)&#10;2025-05-18 18:50:41,828 - INFO - Consolidated data from CSVs into 3 rows before deduplication.&#10;2025-05-18 18:50:41,828 - INFO - Applying deduplication, preferring source: 'Rocket'&#10;2025-05-18 18:50:41,829 - INFO - Found 1 sets of potential duplicate entries based on TxnID before deduplication by preferred source ('Rocket').&#10;2025-05-18 18:50:41,831 - INFO - Removed 2 duplicate transactions, prioritizing 'Rocket'.&#10;2025-05-18 18:50:41,831 - INFO - Final ETL DataFrame contains 1 rows.&#10;2025-05-18 18:50:41,831 - INFO - No canonical data to merge or TxnID missing. Using data directly from ETL process.&#10;2025-05-18 18:50:41,831 - INFO - Reading 'Queue_Review' sheet from C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.xlsm&#10;2025-05-18 18:50:41,927 - ERROR - Error reading 'Queue_Review' sheet: File contains no valid workbook part. Skipping sync.&#10;2025-05-18 18:50:41,927 - INFO - ⚙️  Final DF columns (29): ['TxnID', 'Owner', 'Date', 'PostDate', 'Merchant', 'OriginalDescription', 'Category', 'Amount', 'Tags', 'Institution', 'Account', 'AccountLast4', 'AccountType', 'SharedFlag', 'SplitPercent', 'StatementStart', 'StatementEnd', 'StatementPeriodDesc', 'DataSourceName', 'DataSourceDate', 'ReferenceNumber', 'Note', 'IgnoredFrom', 'TaxDeductible', 'CustomName', 'Currency', 'Extras', 'Description', 'Source']&#10;2025-05-18 18:50:41,927 - INFO - Writing final DataFrame (1 rows) to Parquet: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\balance_final.parquet (Engine: pyarrow, Compression: zstd)&#10;2025-05-18 18:50:41,938 - INFO - Successfully wrote Parquet file on attempt 1/5.&#10;2025-05-18 18:50:41,938 - WARNING - Working with macro-enabled workbook (.xlsm). Using temporary file workaround.&#10;2025-05-18 18:50:41,938 - INFO - Preparing to write output to: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.temp.xlsx&#10;2025-05-18 18:50:41,939 - ERROR - Error reading original workbook sheets for preservation: File contains no valid workbook part&#10;2025-05-18 18:50:41,939 - INFO - Writing 1 rows to 'Transactions' sheet...&#10;2025-05-18 18:50:41,942 - DEBUG - Attempting to create 'Queue_Review' template...&#10;2025-05-18 18:50:41,943 - DEBUG - Found 1 sample rows needing review (SharedFlag is '?' or NA) for template.&#10;2025-05-18 18:50:41,946 - INFO - Created 'Queue_Review' template sheet (with 1 sample rows).&#10;2025-05-18 18:50:41,959 - INFO - ✅ Wrote data to temporary XLSX file: test_workbook.temp.xlsx&#10;2025-05-18 18:50:41,959 - INFO - &#10;==================================================================&#10;2025-05-18 18:50:41,959 - INFO - IMPORTANT: To update your macro-enabled workbook:&#10;2025-05-18 18:50:41,959 - INFO - 1. Ensure your main workbook is CLOSED: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.xlsm&#10;2025-05-18 18:50:41,959 - INFO - 2. Open the temporary file: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.temp.xlsx&#10;2025-05-18 18:50:41,959 - INFO - 3. Open your main workbook: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.xlsm&#10;2025-05-18 18:50:41,959 - INFO - 4. In the temporary file, right-click the 'Transactions' sheet tab -&gt; Move or Copy...&#10;2025-05-18 18:50:41,959 - INFO - 5. In the dialog, select 'test_workbook.xlsm' in 'To book:', check 'Create a copy', click OK.&#10;2025-05-18 18:50:41,959 - INFO - 6. Repeat steps 4-5 for the 'Queue_Review' sheet.&#10;2025-05-18 18:50:41,959 - INFO - 7. Close the temporary file WITHOUT saving.&#10;2025-05-18 18:50:41,959 - INFO - 8. Save your main workbook.&#10;2025-05-18 18:50:41,959 - INFO - 9. You can now delete the temporary file: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.temp.xlsx&#10;2025-05-18 18:50:41,960 - INFO -    (Or use the 'ImportFromTempFile' macro in Excel if available)&#10;2025-05-18 18:50:41,960 - INFO - ==================================================================&#10;&#10;2025-05-18 18:50:41,960 - INFO - ✅ Process completed successfully&#10;2025-05-18 18:50:41,960 - DEBUG - Removed lock file: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.xlsm.lock&#10;&#10;CLI STDERR:&#10;INFO: Reloaded balance_pipeline.ingest module in main().&#10;INFO: Reloaded balance_pipeline.csv_consolidator module in main().">tests\test_cli_integration.py:122: in test_cli_xlsm_processing_creates_temp_file
    assert len(df) == 3, "Transactions sheet should contain 3 txns"
E   AssertionError: Transactions sheet should contain 3 txns
E   assert 1 == 3
E    +  where 1 = len(              TxnID         Owner  ...  Description       Source\n0  2edf2958166561c5  UnknownOwner  ...          NaN  TestSource1\n\n[1 rows x 29 columns])

During handling of the above exception, another exception occurred:
tests\test_cli_integration.py:126: in test_cli_xlsm_processing_creates_temp_file
    pytest.fail(f"Failed to read temp XLSX file: {e}\nCLI STDOUT:\n{result.stdout}\nCLI STDERR:\n{result.stderr}")
E   Failed: Failed to read temp XLSX file: Transactions sheet should contain 3 txns
E   assert 1 == 3
E    +  where 1 = len(              TxnID         Owner  ...  Description       Source\n0  2edf2958166561c5  UnknownOwner  ...          NaN  TestSource1\n\n[1 rows x 29 columns])
E   CLI STDOUT:
E   2025-05-18 18:50:41,789 - DEBUG - Logging configured. Level: DEBUG. Handlers: [None]
E   2025-05-18 18:50:41,789 - INFO - ==================================================
E   2025-05-18 18:50:41,789 - INFO - Starting BALANCE-pyexcel CLI process (full ETL mode)...
E   2025-05-18 18:50:41,789 - DEBUG - Arguments received (full ETL mode): inbox='C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\csv_inbox', workbook='C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.xlsm'
E   2025-05-18 18:50:41,789 - DEBUG - Resolved Inbox Path: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\csv_inbox
E   2025-05-18 18:50:41,789 - DEBUG - Resolved Workbook Path: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.xlsm
E   2025-05-18 18:50:41,790 - DEBUG - Created lock file: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.xlsm.lock
E   2025-05-18 18:50:41,790 - INFO - Canonical Parquet file not found at C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\balance_final.parquet. Will create if not dry run. Starting with empty canonical data.
E   2025-05-18 18:50:41,790 - INFO - Starting ETL process for inbox: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\csv_inbox
E   2025-05-18 18:50:41,791 - INFO - Found 2 CSV files to process: ['data_source1.csv', 'data_source2.csv']
E   2025-05-18 18:50:41,791 - INFO - Loading schema registry from: C:\BALANCE\BALANCE-pyexcel-repository\BALANCE-pyexcel\rules\schema_registry.yml
E   2025-05-18 18:50:41,797 - INFO - Successfully loaded 9 schema definitions.
E   2025-05-18 18:50:41,797 - INFO - Loading merchant lookup rules from: C:\BALANCE\BALANCE-pyexcel-repository\BALANCE-pyexcel\rules\merchant_lookup.csv
E   2025-05-18 18:50:41,799 - INFO - Successfully loaded and compiled 10 merchant lookup rules from C:\BALANCE\BALANCE-pyexcel-repository\BALANCE-pyexcel\rules\merchant_lookup.csv.
E   2025-05-18 18:50:41,799 - INFO - Processing CSV file: data_source1.csv
E   2025-05-18 18:50:41,800 - INFO - Inferred Owner: 'UnknownOwner' from path.
E   2025-05-18 18:50:41,801 - INFO - Matched schema 'test_data_source1' by filename pattern 'data_source1.csv' for file 'data_source1.csv'.
E   2025-05-18 18:50:41,801 - INFO - Header signature also matches for schema 'test_data_source1'.
E   2025-05-18 18:50:41,801 - INFO - Using schema 'test_data_source1' for data_source1.csv.
E   2025-05-18 18:50:41,801 - INFO - Applying schema transformations for schema ID: 'test_data_source1'
E   2025-05-18 18:50:41,801 - WARNING - Column 'Date' (normalized: 'date') defined in schema 'test_data_source1' column_map not found in the CSV file. It will be missing.
E   2025-05-18 18:50:41,801 - WARNING - Column 'Description' (normalized: 'description') defined in schema 'test_data_source1' column_map not found in the CSV file. It will be missing.
E   2025-05-18 18:50:41,801 - WARNING - Column 'Amount' (normalized: 'amount') defined in schema 'test_data_source1' column_map not found in the CSV file. It will be missing.
E   2025-05-18 18:50:41,801 - WARNING - Column 'Account' (normalized: 'account') defined in schema 'test_data_source1' column_map not found in the CSV file. It will be missing.
E   2025-05-18 18:50:41,801 - WARNING - Column 'Category' (normalized: 'category') defined in schema 'test_data_source1' column_map not found in the CSV file. It will be missing.
E   2025-05-18 18:50:41,801 - WARNING - Column 'Bank' (normalized: 'bank') defined in schema 'test_data_source1' column_map not found in the CSV file. It will be missing.
E   2025-05-18 18:50:41,802 - INFO - Applied column mapping. Renamed columns: {}
E   2025-05-18 18:50:41,803 - INFO - Collected unmapped columns into 'Extras': ['Transaction Date', 'Details', 'Value', 'Account Name', 'Bank Name']
E   2025-05-18 18:50:41,803 - WARNING - Amount column 'Amount' not found after mapping. Cannot apply sign rules or ensure numeric type.
E   2025-05-18 18:50:41,803 - INFO - Populated 'DataSourceName' with 'test_data_source1'.
E   2025-05-18 18:50:41,803 - INFO - Added static column 'Source' with value 'TestSource1'.
E   2025-05-18 18:50:41,803 - WARNING - Unexpected column survived mapping: Transaction Date
E   2025-05-18 18:50:41,803 - WARNING - Unexpected column survived mapping: Details
E   2025-05-18 18:50:41,803 - WARNING - Unexpected column survived mapping: Value
E   2025-05-18 18:50:41,803 - WARNING - Unexpected column survived mapping: Account Name
E   2025-05-18 18:50:41,803 - WARNING - Unexpected column survived mapping: Bank Name
E   2025-05-18 18:50:41,803 - WARNING - Neither 'OriginalDescription' nor 'Merchant' column found for merchant cleaning. Returning empty Series.
E   2025-05-18 18:50:41,803 - INFO - Applied final merchant cleaning.
E   2025-05-18 18:50:41,803 - INFO - #x1F6D2 Merchant blanks after clean for file data_source1.csv: 2 (100.00%)
E   2025-05-18 18:50:41,804 - INFO - Generated 'TxnID' column.
E   2025-05-18 18:50:41,813 - INFO - Applying reindex to MASTER_SCHEMA_COLUMNS (element 3: PostDate) with fill_value=pd.NA for data_source1.csv
E   2025-05-18 18:50:41,814 - INFO - Finished processing data_source1.csv. 2 rows added.
E   2025-05-18 18:50:41,814 - INFO - Processing CSV file: data_source2.csv
E   2025-05-18 18:50:41,816 - INFO - Inferred Owner: 'UnknownOwner' from path.
E   2025-05-18 18:50:41,816 - INFO - Matched schema 'test_data_source2' by filename pattern 'data_source2.csv' for file 'data_source2.csv'.
E   2025-05-18 18:50:41,816 - INFO - Header signature also matches for schema 'test_data_source2'.
E   2025-05-18 18:50:41,816 - INFO - Using schema 'test_data_source2' for data_source2.csv.
E   2025-05-18 18:50:41,816 - INFO - Applying schema transformations for schema ID: 'test_data_source2'
E   2025-05-18 18:50:41,816 - WARNING - Column 'Date' (normalized: 'date') defined in schema 'test_data_source2' column_map not found in the CSV file. It will be missing.
E   2025-05-18 18:50:41,816 - WARNING - Column 'Description' (normalized: 'description') defined in schema 'test_data_source2' column_map not found in the CSV file. It will be missing.
E   2025-05-18 18:50:41,816 - WARNING - Column 'Amount' (normalized: 'amount') defined in schema 'test_data_source2' column_map not found in the CSV file. It will be missing.
E   2025-05-18 18:50:41,816 - WARNING - Column 'Account' (normalized: 'account') defined in schema 'test_data_source2' column_map not found in the CSV file. It will be missing.
E   2025-05-18 18:50:41,816 - WARNING - Column 'Category' (normalized: 'category') defined in schema 'test_data_source2' column_map not found in the CSV file. It will be missing.
E   2025-05-18 18:50:41,816 - WARNING - Column 'Bank' (normalized: 'bank') defined in schema 'test_data_source2' column_map not found in the CSV file. It will be missing.
E   2025-05-18 18:50:41,816 - INFO - Applied column mapping. Renamed columns: {}
E   2025-05-18 18:50:41,817 - INFO - Collected unmapped columns into 'Extras': ['Transaction Date', 'Details', 'Value', 'Account Name', 'Bank Name']
E   2025-05-18 18:50:41,817 - WARNING - Amount column 'Amount' not found after mapping. Cannot apply sign rules or ensure numeric type.
E   2025-05-18 18:50:41,817 - INFO - Populated 'DataSourceName' with 'test_data_source2'.
E   2025-05-18 18:50:41,817 - INFO - Added static column 'Source' with value 'TestSource2'.
E   2025-05-18 18:50:41,817 - WARNING - Unexpected column survived mapping: Transaction Date
E   2025-05-18 18:50:41,817 - WARNING - Unexpected column survived mapping: Details
E   2025-05-18 18:50:41,817 - WARNING - Unexpected column survived mapping: Value
E   2025-05-18 18:50:41,817 - WARNING - Unexpected column survived mapping: Account Name
E   2025-05-18 18:50:41,817 - WARNING - Unexpected column survived mapping: Bank Name
E   2025-05-18 18:50:41,817 - WARNING - Neither 'OriginalDescription' nor 'Merchant' column found for merchant cleaning. Returning empty Series.
E   2025-05-18 18:50:41,818 - INFO - Applied final merchant cleaning.
E   2025-05-18 18:50:41,818 - INFO - #x1F6D2 Merchant blanks after clean for file data_source2.csv: 1 (100.00%)
E   2025-05-18 18:50:41,818 - INFO - Generated 'TxnID' column.
E   2025-05-18 18:50:41,826 - INFO - Applying reindex to MASTER_SCHEMA_COLUMNS (element 3: PostDate) with fill_value=pd.NA for data_source2.csv
E   2025-05-18 18:50:41,826 - INFO - Finished processing data_source2.csv. 1 rows added.
E   2025-05-18 18:50:41,826 - INFO - Schema matching smoke test - Counts of schema_ids found: Counter({'test_data_source1': 1, 'test_data_source2': 1})
E   2025-05-18 18:50:41,827 - INFO - Successfully consolidated 2 CSV files into a single DataFrame with 3 total rows.
E   2025-05-18 18:50:41,827 - INFO - #x1F6D2 Total merchant blanks in final_df after concatenation: 0 (0.00%)
E   2025-05-18 18:50:41,828 - INFO - Consolidated data from CSVs into 3 rows before deduplication.
E   2025-05-18 18:50:41,828 - INFO - Applying deduplication, preferring source: 'Rocket'
E   2025-05-18 18:50:41,829 - INFO - Found 1 sets of potential duplicate entries based on TxnID before deduplication by preferred source ('Rocket').
E   2025-05-18 18:50:41,831 - INFO - Removed 2 duplicate transactions, prioritizing 'Rocket'.
E   2025-05-18 18:50:41,831 - INFO - Final ETL DataFrame contains 1 rows.
E   2025-05-18 18:50:41,831 - INFO - No canonical data to merge or TxnID missing. Using data directly from ETL process.
E   2025-05-18 18:50:41,831 - INFO - Reading 'Queue_Review' sheet from C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.xlsm
E   2025-05-18 18:50:41,927 - ERROR - Error reading 'Queue_Review' sheet: File contains no valid workbook part. Skipping sync.
E   2025-05-18 18:50:41,927 - INFO - ⚙️  Final DF columns (29): ['TxnID', 'Owner', 'Date', 'PostDate', 'Merchant', 'OriginalDescription', 'Category', 'Amount', 'Tags', 'Institution', 'Account', 'AccountLast4', 'AccountType', 'SharedFlag', 'SplitPercent', 'StatementStart', 'StatementEnd', 'StatementPeriodDesc', 'DataSourceName', 'DataSourceDate', 'ReferenceNumber', 'Note', 'IgnoredFrom', 'TaxDeductible', 'CustomName', 'Currency', 'Extras', 'Description', 'Source']
E   2025-05-18 18:50:41,927 - INFO - Writing final DataFrame (1 rows) to Parquet: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\balance_final.parquet (Engine: pyarrow, Compression: zstd)
E   2025-05-18 18:50:41,938 - INFO - Successfully wrote Parquet file on attempt 1/5.
E   2025-05-18 18:50:41,938 - WARNING - Working with macro-enabled workbook (.xlsm). Using temporary file workaround.
E   2025-05-18 18:50:41,938 - INFO - Preparing to write output to: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.temp.xlsx
E   2025-05-18 18:50:41,939 - ERROR - Error reading original workbook sheets for preservation: File contains no valid workbook part
E   2025-05-18 18:50:41,939 - INFO - Writing 1 rows to 'Transactions' sheet...
E   2025-05-18 18:50:41,942 - DEBUG - Attempting to create 'Queue_Review' template...
E   2025-05-18 18:50:41,943 - DEBUG - Found 1 sample rows needing review (SharedFlag is '?' or NA) for template.
E   2025-05-18 18:50:41,946 - INFO - Created 'Queue_Review' template sheet (with 1 sample rows).
E   2025-05-18 18:50:41,959 - INFO - ✅ Wrote data to temporary XLSX file: test_workbook.temp.xlsx
E   2025-05-18 18:50:41,959 - INFO - 
E   ==================================================================
E   2025-05-18 18:50:41,959 - INFO - IMPORTANT: To update your macro-enabled workbook:
E   2025-05-18 18:50:41,959 - INFO - 1. Ensure your main workbook is CLOSED: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.xlsm
E   2025-05-18 18:50:41,959 - INFO - 2. Open the temporary file: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.temp.xlsx
E   2025-05-18 18:50:41,959 - INFO - 3. Open your main workbook: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.xlsm
E   2025-05-18 18:50:41,959 - INFO - 4. In the temporary file, right-click the 'Transactions' sheet tab -&gt; Move or Copy...
E   2025-05-18 18:50:41,959 - INFO - 5. In the dialog, select 'test_workbook.xlsm' in 'To book:', check 'Create a copy', click OK.
E   2025-05-18 18:50:41,959 - INFO - 6. Repeat steps 4-5 for the 'Queue_Review' sheet.
E   2025-05-18 18:50:41,959 - INFO - 7. Close the temporary file WITHOUT saving.
E   2025-05-18 18:50:41,959 - INFO - 8. Save your main workbook.
E   2025-05-18 18:50:41,959 - INFO - 9. You can now delete the temporary file: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.temp.xlsx
E   2025-05-18 18:50:41,960 - INFO -    (Or use the 'ImportFromTempFile' macro in Excel if available)
E   2025-05-18 18:50:41,960 - INFO - ==================================================================
E   
E   2025-05-18 18:50:41,960 - INFO - ✅ Process completed successfully
E   2025-05-18 18:50:41,960 - DEBUG - Removed lock file: C:\Users\Ryan\AppData\Local\Temp\pytest-of-Ryan\pytest-22\test_cli_xlsm_processing_creat0\test_workbook.xlsm.lock
E   
E   CLI STDERR:
E   INFO: Reloaded balance_pipeline.ingest module in main().
E   INFO: Reloaded balance_pipeline.csv_consolidator module in main().</failure></testcase><testcase classname="tests.test_cli_integration" name="test_cli_sync_flow_with_parquet_and_queue" time="1.082"><failure message="AssertionError: TX1 not found in final Parquet&#10;assert not True&#10; +  where True = Empty DataFrame\nColumns: [TxnID, Owner, Date, PostDate, Merchant, OriginalDescription, Category, Amount, Tags, Institu...ceDate, ReferenceNumber, Note, IgnoredFrom, TaxDeductible, CustomName, Currency, Extras, Description, Source]\nIndex: [].empty">tests\test_cli_integration.py:216: in test_cli_sync_flow_with_parquet_and_queue
    assert not tx1_df.empty, "TX1 not found in final Parquet"
E   AssertionError: TX1 not found in final Parquet
E   assert not True
E    +  where True = Empty DataFrame\nColumns: [TxnID, Owner, Date, PostDate, Merchant, OriginalDescription, Category, Amount, Tags, Institu...ceDate, ReferenceNumber, Note, IgnoredFrom, TaxDeductible, CustomName, Currency, Extras, Description, Source]\nIndex: [].empty</failure></testcase><testcase classname="tests.test_cli_integration" name="test_cli_queue_review_missing_required_columns[xlsx]" time="0.622"><failure message="assert 1 == 3&#10; +  where 1 = len(              TxnID         Owner  ... Description       Source\n0  2edf2958166561c5  UnknownOwner  ...        None  TestSource1\n\n[1 rows x 29 columns])">tests\test_cli_integration.py:281: in test_cli_queue_review_missing_required_columns
    assert len(final_df) == 3 # 3 transactions from sample_csv_dir
E   assert 1 == 3
E    +  where 1 = len(              TxnID         Owner  ... Description       Source\n0  2edf2958166561c5  UnknownOwner  ...        None  TestSource1\n\n[1 rows x 29 columns])</failure></testcase><testcase classname="tests.test_cli_retry" name="test_parquet_write_succeeds_on_retry" time="0.001" /><testcase classname="tests.test_cli_retry" name="test_parquet_write_fails_after_all_retries" time="0.001" /><testcase classname="tests.test_cross_schema" name="test_multi_schema_load" time="0.011"><failure message="AssertionError: Loaded DataFrame should not be empty (check sample data and paths).&#10;assert not True&#10; +  where True = Empty DataFrame\nColumns: [Owner, Date, PostDate, Description, Amount, Account, AccountLast4, AccountType, Category, Bank, Source]\nIndex: [].empty">tests\test_cross_schema.py:43: in test_multi_schema_load
    assert not df.empty, "Loaded DataFrame should not be empty (check sample data and paths)."
E   AssertionError: Loaded DataFrame should not be empty (check sample data and paths).
E   assert not True
E    +  where True = Empty DataFrame\nColumns: [Owner, Date, PostDate, Description, Amount, Account, AccountLast4, AccountType, Category, Bank, Source]\nIndex: [].empty</failure></testcase><testcase classname="tests.test_csv_consolidator" name="test_process_single_csv_file[Jordyn - Chase Bank - Total Checking x6173 - All.csv-params0]" time="0.021" /><testcase classname="tests.test_csv_consolidator" name="test_process_single_csv_file[Jordyn - Discover - Discover It Card x1544 - CSV.csv-params1]" time="0.020" /><testcase classname="tests.test_csv_consolidator" name="test_process_single_csv_file[Jordyn - Wells Fargo - Active Cash Visa Signature Card x4296 - CSV.csv-params2]" time="0.020" /><testcase classname="tests.test_csv_consolidator" name="test_process_single_csv_file[Ryan - Monarch Money - 041225.csv-params3]" time="0.019" /><testcase classname="tests.test_csv_consolidator" name="test_process_single_csv_file[Ryan - Rocket Money - 041225.csv-params4]" time="0.018" /><testcase classname="tests.test_master_columns" name="test_postdate_spelling" time="0.000" /><testcase classname="tests.test_master_parquet" name="test_append_to_master_parquet" time="0.002"><failure message="AssertionError: Parquet file was not created at C:\BALANCE\BALANCE-pyexcel-repository\BALANCE-pyexcel\data\processed\combined_transactions.parquet&#10;assert False&#10; +  where False = exists()&#10; +    where exists = WindowsPath('C:/BALANCE/BALANCE-pyexcel-repository/BALANCE-pyexcel/data/processed/combined_transactions.parquet').exists">tests\test_master_parquet.py:79: in test_append_to_master_parquet
    assert PARQUET_FILE_PATH.exists(), f"Parquet file was not created at {PARQUET_FILE_PATH}"
E   AssertionError: Parquet file was not created at C:\BALANCE\BALANCE-pyexcel-repository\BALANCE-pyexcel\data\processed\combined_transactions.parquet
E   assert False
E    +  where False = exists()
E    +    where exists = WindowsPath('C:/BALANCE/BALANCE-pyexcel-repository/BALANCE-pyexcel/data/processed/combined_transactions.parquet').exists</failure></testcase><testcase classname="tests.test_merchant" name="test_normalize_merchant[Sq *My Coffee Shop 123-My Coffee Shop]" time="0.000" /><testcase classname="tests.test_merchant" name="test_normalize_merchant[SQ *MY COFFEE SHOP-My Coffee Shop]" time="0.000" /><testcase classname="tests.test_merchant" name="test_normalize_merchant[STARBUCKS 01234-Starbucks]" time="0.000" /><testcase classname="tests.test_merchant" name="test_normalize_merchant[STARBUCKS 999-Starbucks]" time="0.000" /><testcase classname="tests.test_merchant" name="test_normalize_merchant[Wal-Mart #1234-Walmart]" time="0.000" /><testcase classname="tests.test_merchant" name="test_normalize_merchant[WALMART SUPERCENTER-Walmart]" time="0.001"><failure message="AssertionError: assert 'Walmart Supercenter' == 'Walmart'&#10;  &#10;  - Walmart&#10;  + Walmart Supercenter">tests\test_merchant.py:52: in test_normalize_merchant
    assert normalize_merchant(raw) == expected_canon
E   AssertionError: assert 'Walmart Supercenter' == 'Walmart'
E     
E     - Walmart
E     + Walmart Supercenter</failure></testcase><testcase classname="tests.test_merchant" name="test_normalize_merchant[MY LOCAL COFFEE SHOP-My Local Coffee Shop]" time="0.000" /><testcase classname="tests.test_merchant" name="test_normalize_merchant[SAFEWAY 123-Safeway 123]" time="0.000" /><testcase classname="tests.test_merchant" name="test_normalize_merchant[Amazon.com-Amazon Com]" time="0.000" /><testcase classname="tests.test_merchant" name="test_normalize_merchant[AMZN Mktp US-Amzn Mktp Us]" time="0.000" /><testcase classname="tests.test_merchant" name="test_normalize_merchant[SOME VENDOR-Some Vendor]" time="0.000" /><testcase classname="tests.test_merchant" name="test_normalize_merchant[-]" time="0.000" /><testcase classname="tests.test_merchant" name="test_normalize_merchant[None-]" time="0.000" /><testcase classname="tests.test_merchant" name="test_normalize_merchant[  Multiple   Spaces  -Multiple Spaces]" time="0.000" /><testcase classname="tests.test_merchant" name="test_normalize_merchant[Caf\xe9 Accent\xe9-Cafe Accente]" time="0.000" /><testcase classname="tests.test_merchant_cli" name="test_add_merchant_rule_creates_file_with_header" time="0.003" /><testcase classname="tests.test_merchant_cli" name="test_add_merchant_rule_appends_to_existing_file" time="0.002" /><testcase classname="tests.test_merchant_cli" name="test_add_merchant_rule_invalid_regex" time="0.002" /><testcase classname="tests.test_merchant_cli" name="test_add_merchant_rule_canonical_with_comma" time="0.001" /><testcase classname="tests.test_merchant_cli" name="test_cli_merchant_add_happy_path" time="1.622" /><testcase classname="tests.test_merchant_cli" name="test_cli_merchant_add_invalid_regex" time="1.632" /><testcase classname="tests.test_merchant_cli" name="test_cli_merchant_add_canonical_with_comma" time="1.669" /><testcase classname="tests.test_normalize" name="test_clean_merchant_with_csv_rule" time="0.003"><failure message="AssertionError: assert 'My Favorite Coffee Shop' == 'Generic Coffee Place'&#10;  &#10;  - Generic Coffee Place&#10;  + My Favorite Coffee Shop">tests\test_normalize.py:74: in test_clean_merchant_with_csv_rule
    assert normalize.clean_merchant("My Favorite COFFEE SHOP") == "Generic Coffee Place"
E   AssertionError: assert 'My Favorite Coffee Shop' == 'Generic Coffee Place'
E     
E     - Generic Coffee Place
E     + My Favorite Coffee Shop</failure></testcase><testcase classname="tests.test_normalize" name="test_clean_merchant_fallback_behavior" time="0.002" /><testcase classname="tests.test_normalize" name="test_clean_merchant_empty_lookup_file" time="0.002" /><testcase classname="tests.test_normalize" name="test_load_merchant_lookup_invalid_regex_raises_valueerror" time="0.002"><failure message="Failed: DID NOT RAISE &lt;class 'ValueError'&gt;">tests\test_normalize.py:115: in test_load_merchant_lookup_invalid_regex_raises_valueerror
    with pytest.raises(ValueError) as excinfo:
E   Failed: DID NOT RAISE &lt;class 'ValueError'&gt;</failure></testcase><testcase classname="tests.test_normalize" name="test_load_merchant_lookup_file_not_found_uses_fallback" time="0.002"><failure message="AssertionError: assert 'Merchant lookup file not found: C:\\Users\\Ryan\\AppData\\Local\\Temp\\pytest-of-Ryan\\pytest-22\\test_load_merchant_lookup_file0\\does_not_exist.csv' in ''&#10; +  where '' = &lt;_pytest.logging.LogCaptureFixture object at 0x000001C5AA997470&gt;.text">tests\test_normalize.py:134: in test_load_merchant_lookup_file_not_found_uses_fallback
    assert f"Merchant lookup file not found: {non_existent_file}" in caplog.text
E   AssertionError: assert 'Merchant lookup file not found: C:\\Users\\Ryan\\AppData\\Local\\Temp\\pytest-of-Ryan\\pytest-22\\test_load_merchant_lookup_file0\\does_not_exist.csv' in ''
E    +  where '' = &lt;_pytest.logging.LogCaptureFixture object at 0x000001C5AA997470&gt;.text</failure></testcase><testcase classname="tests.test_normalize" name="test_load_merchant_lookup_invalid_header" time="0.002"><failure message="Failed: DID NOT RAISE &lt;class 'ValueError'&gt;">tests\test_normalize.py:155: in test_load_merchant_lookup_invalid_header
    with pytest.raises(ValueError) as excinfo:
E   Failed: DID NOT RAISE &lt;class 'ValueError'&gt;</failure></testcase><testcase classname="tests.test_normalize" name="test_load_merchant_lookup_malformed_row_is_skipped" time="0.003"><failure message="AssertionError: assert 'Skipping malformed row 3' in ''&#10; +  where '' = &lt;_pytest.logging.LogCaptureFixture object at 0x000001C5AA955910&gt;.text">tests\test_normalize.py:176: in test_load_merchant_lookup_malformed_row_is_skipped
    assert "Skipping malformed row 3" in caplog.text # Row 3 is malformed
E   AssertionError: assert 'Skipping malformed row 3' in ''
E    +  where '' = &lt;_pytest.logging.LogCaptureFixture object at 0x000001C5AA955910&gt;.text</failure></testcase><testcase classname="tests.test_normalize" name="test_clean_merchant_handles_non_string_input" time="0.002" /><testcase classname="tests.test_normalize" name="test_normalize_df_minimal_smoke_test" time="0.007" /><testcase classname="tests.test_parquet_selective_load" name="test_selective_column_load_memory_reduction" time="0.070" /><testcase classname="tests.test_parquet_selective_load" name="test_selective_load_handles_missing_columns_gracefully" time="0.005" /><testcase classname="tests.test_pdf_extract" name="test_process_pdfs_script_output" time="1.030" /><testcase classname="tests.test_pdf_extract" name="test_derive_amount_logic" time="0.003" /><testcase classname="tests.test_pdf_ingest" name="test_jordyn_pdf_ingestion_and_normalization" time="0.005"><failure message="Failed: Ingestion returned an empty DataFrame. Check schema matching or file reading.">tests\test_pdf_ingest.py:89: in test_jordyn_pdf_ingestion_and_normalization
    pytest.fail("Ingestion returned an empty DataFrame. Check schema matching or file reading.")
E   Failed: Ingestion returned an empty DataFrame. Check schema matching or file reading.</failure></testcase><testcase classname="tests.test_sync" name="test_sync_empty_transactions" time="0.001" /><testcase classname="tests.test_sync" name="test_sync_empty_queue" time="0.001" /><testcase classname="tests.test_sync" name="test_sync_missing_cols_transactions" time="0.001" /><testcase classname="tests.test_sync" name="test_sync_missing_cols_queue" time="0.001" /><testcase classname="tests.test_sync" name="test_sync_happy_path_y_n_s_updates" time="0.004" /><testcase classname="tests.test_sync" name="test_sync_invalid_decision_value_ignored" time="0.003" /><testcase classname="tests.test_sync" name="test_sync_split_decision_missing_percent_defaults_to_50" time="0.003" /><testcase classname="tests.test_sync" name="test_sync_split_decision_invalid_percent_format_defaults_to_50" time="0.003" /><testcase classname="tests.test_sync" name="test_sync_split_percent_out_of_bounds_clamped" time="0.003" /><testcase classname="tests.test_sync" name="test_sync_txn_id_not_in_transactions_is_ignored" time="0.003" /><testcase classname="tests.test_sync" name="test_sync_case_insensitivity_and_whitespace_in_decision" time="0.003" /><testcase classname="tests.test_sync" name="test_sync_preserves_other_columns" time="0.003" /><testcase classname="tests.test_sync" name="test_sync_split_percent_for_non_s_decision_is_ignored" time="0.005" /><testcase classname="tests.test_sync" name="test_sync_empty_decision_in_queue_is_ignored" time="0.003" /><testcase classname="tests.test_txnid" name="test_txnid_unique_real_file" time="0.005" /><testcase classname="tests.test_txnid" name="test_txnid_differs_by_postdate[2024-01-01-01/01-2024-01-01-01/02]" time="0.000" /><testcase classname="tests.test_txnid" name="test_txnid_differs_by_postdate[2024-08-19-08/19-2024-08-19-08/20]" time="0.000" /></testsuite></testsuites>